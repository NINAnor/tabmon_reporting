---
title: "Rapport TABMON"
format:
  html:
    toc: true
    toc-depth: 2
    code-fold: false
    fig-width: 12
    fig-height: 8
    dpi: 150
  pdf:
    toc: true
    toc-depth: 2
    code-fold: false
    fig-width: 12
    fig-height: 8
    dpi: 150
    template-file: ../custom_template.tex.j2
execute:
  echo: false
  warning: false
  message: false
jupyter: python3
---

```{python}
#| label: imports
#| include: false

import duckdb
import pandas as pd
import os
from datetime import datetime
import matplotlib.pyplot as plt
from IPython.display import Markdown, display
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')
```

```{python}
#| label: autoreload
#| include: false

%load_ext autoreload
%autoreload 2
```

```{python}
#| label: custom-imports
#| include: false

from scripts.utils import load_parquet_batch, get_file_date, get_bugg_id, get_file_paths_for_devices
from scripts.data_processor import DataProcessor
from scripts.plots import (plot_num_recorded_files_per_buggs, 
                            plot_number_detections_per_species, 
                            plot_daily_trends, 
                            plot_daily_trends_full, 
                            plot_daily_trends_full_per_device)
```


```{python}
#| tags: [parameters]

cluster_name = "Port-Cros"
```

```{python}
#| label: parameters
#| include: false

# MODEL PARAMETERS
confidence_threshold = 0.8

# DISPLAY PARAMETERS
N_occurrence_threshold_annual = 20
N_occurrence_threshold_daily = 50
date_tick = 5

# PATH PARAMETERS
BASE_PATH = Path("/home/benjamin.cretois/Code/TABMON/TABMON_reports/")
database_path = BASE_PATH / "data/merged_predictions_light/"
index_path = BASE_PATH / "data/index.parquet"
vuln_status_path = BASE_PATH / "data/european_red_list.xlsx"

# Load multilingual dictionary
birdnet_labels_file = BASE_PATH / "data/BirdNET_GLOBAL_6K_V2.4_Labels.txt"
birdnet_all_labels = birdnet_labels_file.read_text(encoding="utf-8").splitlines()
all_latin_labels = [item.split('_')[0] for item in birdnet_all_labels]
all_english_labels = [item.split('_')[1] for item in birdnet_all_labels]
multilingual_key_dict = dict(zip(all_latin_labels, all_english_labels))

site_info = pd.read_csv(BASE_PATH / 'data/site_info.csv') 

# Set plot parameters
plt.rcParams.update({'font.size': 6})
plt.rcParams["figure.dpi"] = 150
```

```{python}
#| label: setup-cluster-data
#| include: false

cluster_filter = site_info["Cluster"] == cluster_name
deploymentID_list = site_info[cluster_filter]["DeploymentID"].tolist()
bugg_id_list = site_info[cluster_filter]["DeviceID"].tolist()
site_list = site_info[cluster_filter]["Site"].tolist()
deployment_dates = site_info[cluster_filter]["deploymentBeginDate"]

# Remove duplicates while preserving order 
seen = set()
unique_indices = []
for i, bugg_id in enumerate(bugg_id_list):
    if bugg_id not in seen:
        seen.add(bugg_id)
        unique_indices.append(i)

bugg_id_list = [bugg_id_list[i] for i in unique_indices]
site_list = [site_list[i] for i in unique_indices]
deployment_date_list = [datetime.strptime(deployment_dates.iloc[i], "%d/%m/%Y") for i in unique_indices]

N_plot = len(bugg_id_list)
```


```{python}
#| label: setup-file-paths
#| include: false

species_filter = ["Porzana porzana", "Tetrao urogallus"]

# Get all file paths efficiently
all_file_paths = get_file_paths_for_devices(database_path, bugg_id_list)
```

# Recording activity

The microphones record acoustic activity 24 hours a day in 5-minute files and send them via 4G.
The following figure shows the number of recordings received per day for each recorder in the area.
Under normal operating conditions, we should receive 288 files per recorder per day (green line).

The lack of recordings is most often due to a poor connection in the area, but can also be caused by power supply problems (solar panel or battery) or microphone malfunctions.

```{python}
#| label: load-index-data
#| include: false

index_df = duckdb.query(f"SELECT * FROM read_parquet('{index_path}')").to_df()
index_df = index_df[index_df["MimeType"]=='audio/mpeg']
```

```{python}
#| label: filter-index-data
#| include: false

index_df = index_df[list(map(lambda x: x.startswith('bugg_RPiID'), index_df['device']))]
index_df["date"] = index_df.apply(lambda row: get_file_date(row['Name']), axis=1)
index_df = index_df[["date", "Name", "device"]]
index_df["bugg_id"] = index_df.apply(lambda row: get_bugg_id(row['device']), axis=1)
index_df = index_df[index_df["bugg_id"].isin(bugg_id_list)]
```


```{python}
#| label: setup-date-range
#| include: false

full_date_range = pd.date_range(
    start = min(deployment_date_list),
    end=index_df['date'].max(),
    freq='D'  # daily
).date 
```

```{python}
#| label: load-predictions
#| include: false

# Load all predictions efficiently in a single batch operation
predictions_df = load_parquet_batch(all_file_paths, species_filter=species_filter, confidence_threshold=confidence_threshold)

N_tot = predictions_df.shape[0]
predictions_df['common name'] = predictions_df['scientific name'].map(multilingual_key_dict)

if predictions_df['common name'].isnull().sum() > 0:
    untranslated_species = list(set(predictions_df['scientific name'][predictions_df['common name'].isnull()].tolist()))
    print("Translation error", untranslated_species)
```


```{python}
#| label: add-vulnerability-status
#| include: false

# Add the vulnerability status from the IUCN red list
vuln_status = pd.read_excel(vuln_status_path, sheet_name='2021_European Red List', header=2)

predictions_df_with_status = predictions_df.merge(
    vuln_status[['Scientific Name', 'IUCN Red List category (Europe)']],
    left_on='scientific name',
    right_on='Scientific Name',
    how='left'
)

# Create the combined column (common name + IUCN status)
predictions_df_with_status['species_with_status'] = predictions_df_with_status.apply(
    lambda row: f"{row['common name']} ({row['IUCN Red List category (Europe)']})" 
    if pd.notna(row['IUCN Red List category (Europe)']) 
    else row['common name'], 
    axis=1
)

# Drop the extra Scientific Name column from the merge
predictions_df_with_status = predictions_df_with_status.drop('Scientific Name', axis=1)

# Replace the original dataframe
predictions_df = predictions_df_with_status
```

```{python}
#| label: create-data-processor
#| include: false

# to avoid redundant calculations
data_processor = DataProcessor(predictions_df, index_df)
```

```{python}
#| label: plot-recording-activity
#| fig-cap: "Number of recorded files per device and per day"

date_counts_total = plot_num_recorded_files_per_buggs(data_processor, bugg_id_list, site_list, full_date_range, plot_width=5, date_tick=7)
```


```{python}
#| label: setup-analyzed-date-range
#| include: false

analyzed_date_range = pd.date_range(
    start=min(deployment_date_list),
    end=predictions_df['date'].max(),
    freq='D'
).date 
```

# Detected species

```{python}
#| label: detection-explanation
#| output: asis

display(Markdown(f"We are currently using BirdNET to detect bird species present in the recordings. The recordings are divided into 3-second segments before being analysed. For each segment, BirdNET provides a confidence score between 0 and 1 for each species. The following figures show the number of detections per species with a confidence score above {confidence_threshold}."))
```

The number of detections corresponds to the number of 3-second segments in which the species is detected.
The following graph shows the number of detections per species in the area over the entire period. 
It should be noted that throughout the document, the number of detections is displayed on a logarithmic scale.
These data should be treated with caution, particularly for species that have only been detected a few times. These are raw results provided by BirdNET, which have not been manually verified. In addition, BirdNET's performance can vary greatly from one species to another.

```{python}
#| label: plot-species-detections
#| fig-cap: "Number of detections per species over the entire period"

plot_number_detections_per_species(data_processor, 
                                    plot_width=10)
```

# Daily trends

```{python}
#| label: daily-trends-explanation
#| output: asis

display(Markdown(f"The following figure shows the daily activity of each species, indicating the number of detections per hour. Only species with more than {N_occurrence_threshold_daily} detections in total are displayed. Please note that the time shown is UTC time, which is two hours behind our summer time and one hour behind our winter time (e.g. 12:00 UTC = 14:00 in summer)."))
```

```{python}
#| label: plot-daily-trends
#| fig-cap: "Daily activity patterns by species (number of detections per hour)"

plot_daily_trends(data_processor, 
                    N_occurrence_threshold_daily, 
                    plot_width=5, 
                    cluster_name=cluster_name)
```

```{python}
#| label: temporal-trends-explanation
#| output: asis

display(Markdown(f"The following figure shows the evolution of detections day by day. Only species with more than {N_occurrence_threshold_annual} detections in total are displayed."))
```

```{python}
#| label: plot-temporal-trends
#| fig-cap: "Evolution of detections over time by species"

plot_daily_trends_full(
    data_processor, 
    N_occurrence_threshold_annual, 
    analyzed_date_range, 
    date_counts_total, 
    plot_width=5, 
    cluster_name="", 
    date_tick=7
)
```

```{python}
#| label: plot-per-device-trends
#| fig-cap: "Evolution of detections per device"

plot_daily_trends_full_per_device(
    data_processor, 
    bugg_id_list, 
    N_occurrence_threshold_annual, 
    analyzed_date_range, 
    date_tick, 
    plot_width=5, 
    cluster_name=cluster_name, 
    site_list=site_list
)
```